{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ambulance CCTV Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNnjcthDm7VD"
      },
      "source": [
        "# Prerequisites Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfVBASI1ZlvR"
      },
      "source": [
        "OIDv4 Dataset Toolkit Downloader Github Repository [Link](https://github.com/EscVM/OIDv4_ToolKit) and Documentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJI0ED9A5XfU",
        "outputId": "b5f19de8-2711-4934-86a5-4c9043365a35"
      },
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'OIDv4_ToolKit' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYxVW7Jt5OYf",
        "outputId": "8795402e-e2f3-43d3-c7c1-2d950a853621"
      },
      "source": [
        "!pip3 install -r /content/OIDv4_ToolKit/requirements.txt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 3)) (1.19.78)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 5)) (1.25.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv4_ToolKit/requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/OIDv4_ToolKit/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/OIDv4_ToolKit/requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: colorama<0.4.4,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (0.15.2)\n",
            "Requirement already satisfied: botocore==1.20.78 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (1.20.78)\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2; python_version > \"2.7\" in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (4.7.2)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r /content/OIDv4_ToolKit/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.20.78->awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2; python_version > \"2.7\"->awscli->-r /content/OIDv4_ToolKit/requirements.txt (line 3)) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUOcl-IS72O"
      },
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from six import BytesIO\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "from PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras import models\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK570YTRnSgi"
      },
      "source": [
        "# Load the Dataset\n",
        "  Dataset contains 5 classes : \n",
        "*   Ambulance\n",
        "*   Bus\n",
        "*   Car\n",
        "*   Truck\n",
        "*   Van"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m2OvyTtYgC1"
      },
      "source": [
        "## Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeqetTwQSFop",
        "outputId": "915fa8e1-c368-4ee9-b6e2-d63041275a91"
      },
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes Ambulance Truck Van Bus Car --type_csv train --limit 500"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ambulance.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 35413 KB/s, 32 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mAmbulance\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 338 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 338 images in train.\u001b[0m\n",
            "100% 338/338 [03:15<00:00,  1.73it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ambulance of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Truck.\u001b[0m\n",
            "\n",
            "\u001b[95mTruck\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 8078 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in train.\u001b[0m\n",
            "100% 500/500 [04:48<00:00,  1.73it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Truck of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Van.\u001b[0m\n",
            "\n",
            "\u001b[95mVan\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 5378 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in train.\u001b[0m\n",
            "100% 500/500 [04:55<00:00,  1.69it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Van of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Bus.\u001b[0m\n",
            "\n",
            "\u001b[95mBus\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 7293 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in train.\u001b[0m\n",
            "100% 500/500 [04:49<00:00,  1.72it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Bus of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 89465 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in train.\u001b[0m\n",
            "100% 500/500 [04:48<00:00,  1.73it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dZeYNewZNAp"
      },
      "source": [
        "## Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPymj_6ZMp-M",
        "outputId": "255130cf-960a-41e9-ae68-0ddcca63ac80"
      },
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes Ambulance Truck Van Bus Car --type_csv test --limit 500"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ambulance.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 27147 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the test-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 49 MB, 36237 KB/s, 1 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File test-annotations-bbox.csv downloaded into OID/csv_folder/test-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mAmbulance\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 51 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 51 images in test.\u001b[0m\n",
            "100% 51/51 [00:41<00:00,  1.23it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ambulance of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Truck.\u001b[0m\n",
            "\n",
            "\u001b[95mTruck\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 820 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in test.\u001b[0m\n",
            "100% 500/500 [05:21<00:00,  1.55it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Truck of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Van.\u001b[0m\n",
            "\n",
            "\u001b[95mVan\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 420 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 420 images in test.\u001b[0m\n",
            "100% 420/420 [04:28<00:00,  1.56it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Van of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Bus.\u001b[0m\n",
            "\n",
            "\u001b[95mBus\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 247 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 247 images in test.\u001b[0m\n",
            "100% 247/247 [02:46<00:00,  1.48it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Bus of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 14663 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in test.\u001b[0m\n",
            "100% 500/500 [05:23<00:00,  1.55it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhajIi3f3i_A"
      },
      "source": [
        "## Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1QhzPva3pUj",
        "outputId": "712abab9-e30e-45f8-a6fb-dd11d6c012a7"
      },
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes Ambulance Truck Van Bus Car --type_csv validation --limit 500"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ambulance.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 16 MB, 46147 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mAmbulance\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 12 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 12 images in validation.\u001b[0m\n",
            "100% 12/12 [00:11<00:00,  1.01it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ambulance of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Truck.\u001b[0m\n",
            "\n",
            "\u001b[95mTruck\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 269 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 269 images in validation.\u001b[0m\n",
            "100% 269/269 [03:02<00:00,  1.48it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Truck of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Van.\u001b[0m\n",
            "\n",
            "\u001b[95mVan\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 141 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 141 images in validation.\u001b[0m\n",
            "100% 141/141 [01:38<00:00,  1.43it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Van of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Bus.\u001b[0m\n",
            "\n",
            "\u001b[95mBus\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 73 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 73 images in validation.\u001b[0m\n",
            "100% 73/73 [00:54<00:00,  1.34it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Bus of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Car.\u001b[0m\n",
            "\n",
            "\u001b[95mCar\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 4900 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 500 images.\u001b[0m\n",
            "    [INFO] | Download of 500 images in validation.\u001b[0m\n",
            "100% 500/500 [05:30<00:00,  1.51it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Car of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgmcuQ39TQF3"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU6lpW9vHnQA"
      },
      "source": [
        "### Normalize and Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa1orFtfc2Y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab80b23-1575-45dd-9a97-1642e048bc6d"
      },
      "source": [
        "# Training Dataset Normalize and Augmentation\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    rotation_range=40,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "test_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        "    )\n",
        "\n",
        "validation_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        "    )\n",
        "\n",
        "traindir = \"/content/OID/Dataset/train\" \n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    traindir,\n",
        "    target_size =(224,224),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        "    )\n",
        "\n",
        "testdir = \"/content/OID/Dataset/test\"\n",
        "\n",
        "test_generator=test_datagen.flow_from_directory(\n",
        "    testdir,\n",
        "    target_size =(224,224),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        "    )\n",
        "\n",
        "valdir = \"/content/OID/Dataset/validation\"\n",
        "\n",
        "validation_generator=validation_datagen.flow_from_directory(\n",
        "    valdir,\n",
        "    target_size =(224,224),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=64\n",
        "    )\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    np.unique(train_generator.classes),\n",
        "    train_generator.classes\n",
        "    )\n",
        "\n",
        "print(train_generator.labels)\n",
        "print(train_generator.class_indices)\n",
        "print(class_weights)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2338 images belonging to 5 classes.\n",
            "Found 1718 images belonging to 5 classes.\n",
            "Found 995 images belonging to 5 classes.\n",
            "[0 0 0 ... 4 4 4]\n",
            "{'Ambulance': 0, 'Bus': 1, 'Car': 2, 'Truck': 3, 'Van': 4}\n",
            "[1.38343195 0.9352     0.9352     0.9352     0.9352    ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsATjHLjTYhK"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQwyOKeQPg0R"
      },
      "source": [
        "## coba model mobilenet v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlIyOMDkyqe3"
      },
      "source": [
        "def format_prediction_string(testdir, result):\n",
        "    prediction_strings = []\n",
        "    \n",
        "    for i in range(len(result['detection_scores'])):\n",
        "        class_name = result['detection_class_names'][i].decode(\"utf-8\")\n",
        "        YMin,XMin,YMax,XMax = result['detection_boxes'][i]\n",
        "        score = result['detection_scores'][i]\n",
        "        \n",
        "        prediction_strings.append(\n",
        "            f\"{class_name} {score} {XMin} {YMin} {XMax} {YMax}\"\n",
        "        )\n",
        "        \n",
        "    prediction_string = \" \".join(prediction_strings)\n",
        "\n",
        "    return {\n",
        "        \"ImageID\": testdir,\n",
        "        \"PredictionString\": prediction_string\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514NB8E-KXKe"
      },
      "source": [
        "def display_image(image):\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    plt.grid(False)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7PxYJpML_Bd"
      },
      "source": [
        " def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
        "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "    colors = list(ImageColor.colormap.values())\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\n",
        "            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "            25)\n",
        "    except IOError:\n",
        "        print(\"Font not found, using default font.\")\n",
        "        font = ImageFont.load_default()\n",
        "    for i in range(min(boxes.shape[0], max_boxes)):\n",
        "        if scores[i] >= min_score:\n",
        "            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n",
        "            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
        "                                           int(100 * scores[i]))\n",
        "            color = colors[hash(class_names[i]) % len(colors)]\n",
        "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "            draw_bounding_box_on_image(\n",
        "                image_pil,\n",
        "                ymin,\n",
        "                xmin,\n",
        "                ymax,\n",
        "                xmax,\n",
        "                color,\n",
        "                font,\n",
        "                display_str_list=[display_str])\n",
        "            np.copyto(image, np.array(image_pil))\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "gkQ98s8KWv-W",
        "outputId": "699d373b-be16-40d3-fd0f-566b185120b5"
      },
      "source": [
        "sample_image_path = \"../input/test/6beb79b52308112d.jpg\"\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # Create our inference graph\n",
        "    image_string_placeholder = tf.placeholder(tf.string)\n",
        "    decoded_image = tf.image.decode_jpeg(image_string_placeholder)\n",
        "    decoded_image_float = tf.image.convert_image_dtype(\n",
        "        image=decoded_image, dtype=tf.float32\n",
        "    )\n",
        "    # Expanding image from (height, width, 3) to (1, height, width, 3)\n",
        "    image_tensor = tf.expand_dims(decoded_image_float, 0)\n",
        "\n",
        "    # Load the model from tfhub.dev, and create a detector_output tensor\n",
        "    model_url = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
        "    detector = hub.Module(model_url)\n",
        "    detector_output = detector(image_tensor, as_dict=True)\n",
        "    # Initialize the Session\n",
        "    init_ops = [tf.global_variables_initializer(), tf.tables_initializer()]\n",
        "    sess = tf.Session()\n",
        "    sess.run(init_ops)\n",
        "\n",
        "    # Load our sample image into a binary string\n",
        "    with tf.gfile.Open(sample_image_path, \"rb\") as binfile:\n",
        "        image_string = binfile.read()\n",
        "\n",
        "    # Run the graph we just created\n",
        "    result_out, image_out = sess.run(\n",
        "        [detector_output, decoded_image],\n",
        "        feed_dict={image_string_placeholder: image_string}\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c0e7f4980b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Create our inference graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage_string_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdecoded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_string_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     decoded_image_float = tf.image.convert_image_dtype(\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxmPO8tarI5"
      },
      "source": [
        "## Coba Transfer Learning\n",
        "ImageNet V2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJw0AETA2JB"
      },
      "source": [
        "### Create Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKU8lDQaphI",
        "outputId": "96613782-fc0f-4e7c-bd34-719676ca478e"
      },
      "source": [
        "IMG_SIZE = (224,224)\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apGAJ2dUA_qS"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKdK7QwVp1i7",
        "outputId": "a63a7510-4aef-4c76-e98d-863fc8e015ad"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_generator))\n",
        "\n",
        "feature_batch = base_model(image_batch)\n",
        "\n",
        "#Freeze the convolutional layers\n",
        "base_model.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "\n",
        "prediction_layer = tf.keras.layers.Dense(5)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "\n",
        "#Model Building\n",
        "inputs = tf.keras.Input(shape=( 224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "print(feature_batch.shape)\n",
        "print(feature_batch_average.shape)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 7, 7, 1280)\n",
            "(64, 1280)\n",
            "(64, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe8AWe-D_fXA"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBAllbvu2luV",
        "outputId": "1a9b694e-ba44-489d-ba99-a5754027a3db"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tNZSVUBAKG0",
        "outputId": "072f6c7e-d0df-4e23-8e90-537032134390"
      },
      "source": [
        "initial_epochs = 10\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(validation_generator)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 54s 3s/step - loss: 1.6228 - accuracy: 0.4354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ekp7y7AuQF"
      },
      "source": [
        "### Re-Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks4uj7JlAfDQ",
        "outputId": "82ec704d-9b4a-4edf-fdb7-6f5eeb9a9b7b"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_generator)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 200s 5s/step - loss: 1.8789 - accuracy: 0.2023 - val_loss: 1.5142 - val_accuracy: 0.3739\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 179s 5s/step - loss: 1.7148 - accuracy: 0.2070 - val_loss: 1.5312 - val_accuracy: 0.3005\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 179s 5s/step - loss: 1.7099 - accuracy: 0.2096 - val_loss: 1.5500 - val_accuracy: 0.2985\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 179s 5s/step - loss: 1.7020 - accuracy: 0.2092 - val_loss: 1.5595 - val_accuracy: 0.2643\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 187s 5s/step - loss: 1.6738 - accuracy: 0.2271 - val_loss: 1.5683 - val_accuracy: 0.2372\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 178s 5s/step - loss: 1.6790 - accuracy: 0.2177 - val_loss: 1.5649 - val_accuracy: 0.2965\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 178s 5s/step - loss: 1.6766 - accuracy: 0.2117 - val_loss: 1.5725 - val_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 178s 5s/step - loss: 1.6764 - accuracy: 0.2391 - val_loss: 1.6035 - val_accuracy: 0.1849\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 179s 5s/step - loss: 1.6598 - accuracy: 0.2250 - val_loss: 1.6088 - val_accuracy: 0.1869\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 179s 5s/step - loss: 1.6563 - accuracy: 0.2250 - val_loss: 1.5862 - val_accuracy: 0.2442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BmvQINOKE9m"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUhKQZl-JD3H",
        "outputId": "62491bc2-65e4-4557-8a0b-57608e23dc79"
      },
      "source": [
        "#Un-Freeze Top Layer\n",
        "base_model.trainable = True\n",
        "\n",
        "# Total Layer on Based Model\n",
        "print(\"Total Layer on Based Model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Layer on Based Model:  154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSm3CD6RJbza"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjCDL9aDJhuY",
        "outputId": "2a7cb215-c991-43f6-cd3c-43fe150f6671"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 1,867,845\n",
            "Non-trainable params: 396,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnuE_VE4J4Yg",
        "outputId": "95bd0c99-26b1-43a6-d42a-b82383f09e17"
      },
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_generator,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_generator)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/20\n",
            "37/37 [==============================] - 243s 6s/step - loss: 1.6636 - accuracy: 0.2246 - val_loss: 1.6960 - val_accuracy: 0.1186\n",
            "Epoch 11/20\n",
            "37/37 [==============================] - 234s 6s/step - loss: 1.6098 - accuracy: 0.2092 - val_loss: 1.5419 - val_accuracy: 0.1548\n",
            "Epoch 12/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5942 - accuracy: 0.2083 - val_loss: 1.5793 - val_accuracy: 0.0734\n",
            "Epoch 13/20\n",
            "37/37 [==============================] - 231s 6s/step - loss: 1.5940 - accuracy: 0.2100 - val_loss: 1.5717 - val_accuracy: 0.2804\n",
            "Epoch 14/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5699 - accuracy: 0.2641 - val_loss: 1.5080 - val_accuracy: 0.4060\n",
            "Epoch 15/20\n",
            "37/37 [==============================] - 233s 6s/step - loss: 1.5729 - accuracy: 0.2436 - val_loss: 1.6438 - val_accuracy: 0.1608\n",
            "Epoch 16/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5757 - accuracy: 0.2419 - val_loss: 1.6919 - val_accuracy: 0.1095\n",
            "Epoch 17/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5683 - accuracy: 0.2520 - val_loss: 1.6206 - val_accuracy: 0.1698\n",
            "Epoch 18/20\n",
            "37/37 [==============================] - 238s 6s/step - loss: 1.5759 - accuracy: 0.2443 - val_loss: 1.6083 - val_accuracy: 0.2241\n",
            "Epoch 19/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5707 - accuracy: 0.2480 - val_loss: 1.6546 - val_accuracy: 0.1910\n",
            "Epoch 20/20\n",
            "37/37 [==============================] - 232s 6s/step - loss: 1.5738 - accuracy: 0.2328 - val_loss: 1.6099 - val_accuracy: 0.0925\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}